data.diff <- data.t[grp1, ] - data.t[grp2, ]
V <- apply(data.diff, 2, function(x) sum(rank(abs(x))[x >
0]))
topscore <- (n1 * (n1 + 1))/2
V.lower <- ifelse(V > topscore/2, topscore - V, V)
if (sum(grp1) < 50) {
V.p <- psignrank(V.lower, n1) * 2
return(ifelse(V.p > 1, 1, V.p))
}
else {
V.std <- (topscore/2 - V.lower)/sqrt(n1 * (n1 + 1) *
(2 * n1 + 1)/24)
return(pnorm(V.std, lower.tail = FALSE) * 2)
}
}
else {
W.std <- multtest::mt.teststat(data, as.numeric(grp1),
test = "wilcoxon")
if (sum(grp1) < 50 && sum(grp2) < 50) {
W.var <- sqrt((n1 * n2) * (n1 + n2 + 1)/12)
W <- abs(W.std) * W.var + (n1 * n2)/2
W.p <- pwilcox(W - 1, n1, n2, lower.tail = FALSE) *
2
return(ifelse(W.p > 1, 1, W.p))
}
else {
return(pnorm(abs(W.std), lower.tail = FALSE) * 2)
}
}
}
t.fast <- function (data, group, paired)
{
grp1 <- group == unique(group)[1]
grp2 <- group == unique(group)[2]
n1 <- sum(grp1)
n2 <- sum(grp2)
if (paired) {
if (n1 != n2)
stop("Cannot pair uneven groups.")
i.1 <- which(grp1)
i.2 <- which(grp2)
paired.order <- unlist(lapply(1:length(i.1), function(i) c(i.1[i],
i.2[i])))
t <- multtest::mt.teststat(data[, paired.order], as.numeric(grp1)[paired.order],
test = "pairt", nonpara = "n")
df <- length(i.1) - 1
return(pt(abs(t), df = df, lower.tail = FALSE) * 2)
}
else {
t <- multtest::mt.teststat(data, as.numeric(grp1), test = "t",
nonpara = "n")
s1 <- apply(data[, grp1], 1, sd)
s2 <- apply(data[, grp2], 1, sd)
df <- ((s1^2/n1 + s2^2/n2)^2)/((s1^2/n1)^2/(n1 - 1) +
(s2^2/n2)^2/(n2 - 1))
return(t)
return(pt(abs(t), df = df, lower.tail = FALSE) * 2)
}
}
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[1,]))))
qq = unlist(c(t.test.res[1,]))
sum(qq <-2)
sum(qq < -2)
qq
qq = unlist(c(t.test.res[1,]))
sum(qq < -2)
sum(qq > -2)
sum(qq > 2)
plot(density(unlist(c(t.test.res[2,]))))
plot(density(unlist(c(t.test.res[15,]))))
plot(density(unlist(c(t.test.res[16,]))))
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = .1)
aldex.ttest2 <- function (clr, paired.test = FALSE, hist.plot = FALSE, verbose = FALSE)
{
conditions <- clr@conds
if (length(unique(conditions)) != 2) {
stop("Please define the aldex.clr object for a vector of two unique 'conditions'.")
}
smpl.ids <- getSampleIDs(clr)
feature.names <- getFeatureNames(clr)
feature.number <- numFeatures(clr)
mc.instances <- numMCInstances(clr)
conditions <- as.factor(conditions)
levels <- levels(conditions)
if (length(conditions) != numConditions(clr)) {
stop(paste("mismatch btw 'length(conditions)' and 'length(names(clr))'. len(condtitions):",
length(conditions), "len(names(clr)):", numConditions(clr)))
}
if (length(levels) != 2)
stop("only two condition levels are currently supported")
levels <- vector("list", length(levels))
names(levels) <- levels(conditions)
sets <- names(levels)
setAsBinary <- as.numeric(conditions == sets[1])
setA <- which(conditions == sets[1])
setB <- which(conditions == sets[2])
wi.p.matrix <- as.data.frame(matrix(1, nrow = feature.number,
ncol = mc.instances))
wi.BH.matrix <- wi.p.matrix
we.p.matrix <- wi.p.matrix
we.BH.matrix <- wi.p.matrix
if (verbose)
message("running tests for each MC instance:")
mc.all <- getMonteCarloInstances(clr)
for (mc.i in 1:mc.instances) {
if (verbose)
numTicks <- progress(mc.i, mc.instances, numTicks)
t.input <- sapply(mc.all, function(y) {
y[, mc.i]
})
wi.p.matrix[, mc.i] <- wilcox.fast(t.input, setAsBinary,
paired.test)
wi.BH.matrix[, mc.i] <- p.adjust(wi.p.matrix[, mc.i],
method = "BH")
we.p.matrix[, mc.i] <- t.fast(t.input, setAsBinary, paired.test)
we.BH.matrix[, mc.i] <- p.adjust(we.p.matrix[, mc.i],
method = "BH")
}
if (hist.plot == TRUE) {
par(mfrow = c(2, 2))
hist(we.p.matrix[, 1], breaks = 99, main = "Welch's P values Instance 1")
hist(wi.p.matrix[, 1], breaks = 99, main = "Wilcoxon P values Instance 1")
hist(we.BH.matrix[, 1], breaks = 99, main = "Welch's BH values Instance 1")
hist(wi.BH.matrix[, 1], breaks = 99, main = "Wilcoxon BH values Instance 1")
par(mfrow = c(1, 1))
}
we.ep <- rowMeans(we.p.matrix)
we.eBH <- rowMeans(we.BH.matrix)
return(we.p.matrix)
}
wilcox.fast <- function (data, group, paired)
{
if (ncol(data) != length(group))
stop("Use rows for feature data.")
grp1 <- group == unique(group)[1]
grp2 <- group == unique(group)[2]
n1 <- sum(grp1)
n2 <- sum(grp2)
data.t <- t(data)
if (paired) {
anyTies <- any(apply(data.t[grp1, ] - data.t[grp2, ],
2, function(x) length(unique(x))) != ncol(data)/2)
}
else {
anyTies <- any(apply(data.t, 2, function(x) length(unique(x))) !=
ncol(data))
}
if (anyTies) {
return(apply(data.t, 2, function(i) {
wilcox.test(x = i[grp1], y = i[grp2], paired = paired,
correct = FALSE)$p.value
}))
}
if (paired) {
if (n1 != n2)
stop("Cannot pair uneven groups.")
data.diff <- data.t[grp1, ] - data.t[grp2, ]
V <- apply(data.diff, 2, function(x) sum(rank(abs(x))[x >
0]))
topscore <- (n1 * (n1 + 1))/2
V.lower <- ifelse(V > topscore/2, topscore - V, V)
if (sum(grp1) < 50) {
V.p <- psignrank(V.lower, n1) * 2
return(ifelse(V.p > 1, 1, V.p))
}
else {
V.std <- (topscore/2 - V.lower)/sqrt(n1 * (n1 + 1) *
(2 * n1 + 1)/24)
return(pnorm(V.std, lower.tail = FALSE) * 2)
}
}
else {
W.std <- multtest::mt.teststat(data, as.numeric(grp1),
test = "wilcoxon")
if (sum(grp1) < 50 && sum(grp2) < 50) {
W.var <- sqrt((n1 * n2) * (n1 + n2 + 1)/12)
W <- abs(W.std) * W.var + (n1 * n2)/2
W.p <- pwilcox(W - 1, n1, n2, lower.tail = FALSE) *
2
return(ifelse(W.p > 1, 1, W.p))
}
else {
return(pnorm(abs(W.std), lower.tail = FALSE) * 2)
}
}
}
t.fast <- function (data, group, paired)
{
grp1 <- group == unique(group)[1]
grp2 <- group == unique(group)[2]
n1 <- sum(grp1)
n2 <- sum(grp2)
if (paired) {
if (n1 != n2)
stop("Cannot pair uneven groups.")
i.1 <- which(grp1)
i.2 <- which(grp2)
paired.order <- unlist(lapply(1:length(i.1), function(i) c(i.1[i],
i.2[i])))
t <- multtest::mt.teststat(data[, paired.order], as.numeric(grp1)[paired.order],
test = "pairt", nonpara = "n")
df <- length(i.1) - 1
return(pt(abs(t), df = df, lower.tail = FALSE) * 2)
}
else {
t <- multtest::mt.teststat(data, as.numeric(grp1), test = "t",
nonpara = "n")
s1 <- apply(data[, grp1], 1, sd)
s2 <- apply(data[, grp2], 1, sd)
df <- ((s1^2/n1 + s2^2/n2)^2)/((s1^2/n1)^2/(n1 - 1) +
(s2^2/n2)^2/(n2 - 1))
return(t)
return(pt(abs(t), df = df, lower.tail = FALSE) * 2)
}
}
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[16,]))))
View(t.test.res)
library(driver)
library(tidyverse)
create_true_abundances <- function(d, n){
dd <- length(d)/2
dat <- d %>%
sapply(function(x) rpois(n, lambda=x)) %>%
t() %>%
as.data.frame() %>%
split(rep(1:2, each=dd)) %>%
purrr::map(~`rownames<-`(.x, paste0("Taxa", 1:dd))) %>%
purrr::map(t) %>%
do.call(rbind, .) %>%
as.data.frame() %>%
cbind(Condition=factor(rep(c(1, 2), each=n)), .) %>%
#cbind(Condition=factor(rep(c("Pre", "Post"), each=n), levels = c("Pre", "Post")), .) %>%
`rownames<-`(., NULL)
return(dat)
}
resample_data <- function(dat, seq.depth){
ddat <- driver::miniclo(as.matrix(dat[,-1]))
for (i in 1:nrow(dat)){
dat[i,-1] <- rmultinom(1, size=seq.depth, prob=ddat[i,])
}
return(dat)
}
d <- c(4000, 4000, 4000, 4000, 4000, 400,400,400,400,4000,400,500,500,500,400,400,400,400,400,100,400, # Pre
4000, 4000, 3000, 2000, 4000, 400,400,400,400,4000,400,500,500,500,200,400,400,400,400,100,100) # Post
dd = length(d)/2
n <- 500
truth1 <- !(d[1:dd]==d[(dd+1):(2*dd)])##testing if the mean is different
dat <- create_true_abundances(d, n=n)
rdat <- resample_data(dat, seq.depth=5000)
rdat2 <- rdat[,-1]
clr_rdat <- driver::clr_array(rdat2, parts = 2)
t.test(clr_rdat[1:n,1],clr_rdat[(n+1):(2*n),1])
library(ALDEx2)
mod <- aldex(t(rdat[,-1]),rdat[,1])
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = .1)
aldex.ttest2 <- function (clr, paired.test = FALSE, hist.plot = FALSE, verbose = FALSE)
{
conditions <- clr@conds
if (length(unique(conditions)) != 2) {
stop("Please define the aldex.clr object for a vector of two unique 'conditions'.")
}
smpl.ids <- getSampleIDs(clr)
feature.names <- getFeatureNames(clr)
feature.number <- numFeatures(clr)
mc.instances <- numMCInstances(clr)
conditions <- as.factor(conditions)
levels <- levels(conditions)
if (length(conditions) != numConditions(clr)) {
stop(paste("mismatch btw 'length(conditions)' and 'length(names(clr))'. len(condtitions):",
length(conditions), "len(names(clr)):", numConditions(clr)))
}
if (length(levels) != 2)
stop("only two condition levels are currently supported")
levels <- vector("list", length(levels))
names(levels) <- levels(conditions)
sets <- names(levels)
setAsBinary <- as.numeric(conditions == sets[1])
setA <- which(conditions == sets[1])
setB <- which(conditions == sets[2])
wi.p.matrix <- as.data.frame(matrix(1, nrow = feature.number,
ncol = mc.instances))
wi.BH.matrix <- wi.p.matrix
we.p.matrix <- wi.p.matrix
we.BH.matrix <- wi.p.matrix
if (verbose)
message("running tests for each MC instance:")
mc.all <- getMonteCarloInstances(clr)
for (mc.i in 1:mc.instances) {
if (verbose)
numTicks <- progress(mc.i, mc.instances, numTicks)
t.input <- sapply(mc.all, function(y) {
y[, mc.i]
})
wi.p.matrix[, mc.i] <- wilcox.fast(t.input, setAsBinary,
paired.test)
wi.BH.matrix[, mc.i] <- p.adjust(wi.p.matrix[, mc.i],
method = "BH")
we.p.matrix[, mc.i] <- t.fast(t.input, setAsBinary, paired.test)
we.BH.matrix[, mc.i] <- p.adjust(we.p.matrix[, mc.i],
method = "BH")
}
if (hist.plot == TRUE) {
par(mfrow = c(2, 2))
hist(we.p.matrix[, 1], breaks = 99, main = "Welch's P values Instance 1")
hist(wi.p.matrix[, 1], breaks = 99, main = "Wilcoxon P values Instance 1")
hist(we.BH.matrix[, 1], breaks = 99, main = "Welch's BH values Instance 1")
hist(wi.BH.matrix[, 1], breaks = 99, main = "Wilcoxon BH values Instance 1")
par(mfrow = c(1, 1))
}
we.ep <- rowMeans(we.p.matrix)
we.eBH <- rowMeans(we.BH.matrix)
return(we.p.matrix)
}
wilcox.fast <- function (data, group, paired)
{
if (ncol(data) != length(group))
stop("Use rows for feature data.")
grp1 <- group == unique(group)[1]
grp2 <- group == unique(group)[2]
n1 <- sum(grp1)
n2 <- sum(grp2)
data.t <- t(data)
if (paired) {
anyTies <- any(apply(data.t[grp1, ] - data.t[grp2, ],
2, function(x) length(unique(x))) != ncol(data)/2)
}
else {
anyTies <- any(apply(data.t, 2, function(x) length(unique(x))) !=
ncol(data))
}
if (anyTies) {
return(apply(data.t, 2, function(i) {
wilcox.test(x = i[grp1], y = i[grp2], paired = paired,
correct = FALSE)$p.value
}))
}
if (paired) {
if (n1 != n2)
stop("Cannot pair uneven groups.")
data.diff <- data.t[grp1, ] - data.t[grp2, ]
V <- apply(data.diff, 2, function(x) sum(rank(abs(x))[x >
0]))
topscore <- (n1 * (n1 + 1))/2
V.lower <- ifelse(V > topscore/2, topscore - V, V)
if (sum(grp1) < 50) {
V.p <- psignrank(V.lower, n1) * 2
return(ifelse(V.p > 1, 1, V.p))
}
else {
V.std <- (topscore/2 - V.lower)/sqrt(n1 * (n1 + 1) *
(2 * n1 + 1)/24)
return(pnorm(V.std, lower.tail = FALSE) * 2)
}
}
else {
W.std <- multtest::mt.teststat(data, as.numeric(grp1),
test = "wilcoxon")
if (sum(grp1) < 50 && sum(grp2) < 50) {
W.var <- sqrt((n1 * n2) * (n1 + n2 + 1)/12)
W <- abs(W.std) * W.var + (n1 * n2)/2
W.p <- pwilcox(W - 1, n1, n2, lower.tail = FALSE) *
2
return(ifelse(W.p > 1, 1, W.p))
}
else {
return(pnorm(abs(W.std), lower.tail = FALSE) * 2)
}
}
}
t.fast <- function (data, group, paired)
{
grp1 <- group == unique(group)[1]
grp2 <- group == unique(group)[2]
n1 <- sum(grp1)
n2 <- sum(grp2)
if (paired) {
if (n1 != n2)
stop("Cannot pair uneven groups.")
i.1 <- which(grp1)
i.2 <- which(grp2)
paired.order <- unlist(lapply(1:length(i.1), function(i) c(i.1[i],
i.2[i])))
t <- multtest::mt.teststat(data[, paired.order], as.numeric(grp1)[paired.order],
test = "pairt", nonpara = "n")
df <- length(i.1) - 1
return(pt(abs(t), df = df, lower.tail = FALSE) * 2)
}
else {
t <- multtest::mt.teststat(data, as.numeric(grp1), test = "t",
nonpara = "n")
s1 <- apply(data[, grp1], 1, sd)
s2 <- apply(data[, grp2], 1, sd)
df <- ((s1^2/n1 + s2^2/n2)^2)/((s1^2/n1)^2/(n1 - 1) +
(s2^2/n2)^2/(n2 - 1))
return(t)
return(pt(abs(t), df = df, lower.tail = FALSE) * 2)
}
}
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[16,]))))
dim(rdat)
scale.samps <- matrix(rnorm(128*1000))
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = scale.samps)
scale.samps <- matrix(rnorm(128*1000),nrow=128)
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = scale.samps)
scale.samps <- matrix(rnorm(128*1000),ncol=128)
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = scale.samps)
warnings
warnings()
scale.samps <- matrix(rlnorm(128*1000),ncol=128)
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = scale.samps)
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[16,]))))
scale.samps <- matrix(rlnorm(128*1000, sd = 6),ncol=128)
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = scale.samps)
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[16,]))))
scale.samps <- matrix(rlnorm(128*1000, sd = 1),ncol=128)
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = scale.samps)
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[16,]))))
zz = unlist(c(t.test.res[1,]))
summary(zz)
log(scale.samps)
scale.samps <- matrix(rlnorm(128*1000, sd = .25),ncol=128)
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = scale.samps)
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[16,]))))
plot(density(unlist(c(t.test.res[1,]))))
d <- c(4000, 4000, 4000, 4000, 4000, 400,400,400,400,4000,400,500,500,500,400,400,400,400,400,100,400, # Pre
4000, 4000, 4000, 4000, 4000, 400,400,400,400,4000,400,500,500,500,200,400,400,400,400,100,100) # Post
dd = length(d)/2
n <- 500
truth1 <- !(d[1:dd]==d[(dd+1):(2*dd)])##testing if the mean is different
dat <- create_true_abundances(d, n=n)
rdat <- resample_data(dat, seq.depth=5000)
rdat2 <- rdat[,-1]
clr_rdat <- driver::clr_array(rdat2, parts = 2)
t.test(clr_rdat[1:n,1],clr_rdat[(n+1):(2*n),1])
library(ALDEx2)
mod <- aldex(t(rdat[,-1]),rdat[,1])
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = .1)
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = 1e-1)
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[1,]))))
##T-test
mu = 0
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = 1)
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[1,]))))
clr@dirichletData
View(clr@analysisData[[1]])
View(clr@dirichletData[[1]])
scale.samps <- matrix(rlnorm(128*1000, sd = .5),ncol=128)
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = 1)
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[1,]))))
mean(t.test.res)
mean(unlist(c(t.test.res[1,])))
scale.samps <- matrix(rlnorm(128*1000, sd = .25),ncol=128)
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = 1)
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[1,]))))
zz <- mean(unlist(c(t.test.res[1,])))
zz <- unlist(c(t.test.res[1,]))
mean(zz)
scale.samps <- matrix(rlnorm(128*1000, sd = .1),ncol=128)
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = 1)
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[1,]))))
zz <- unlist(c(t.test.res[1,]))
mean(zz)
n <- 50
truth1 <- !(d[1:dd]==d[(dd+1):(2*dd)])##testing if the mean is different
dat <- create_true_abundances(d, n=n)
rdat <- resample_data(dat, seq.depth=5000)
rdat2 <- rdat[,-1]
clr_rdat <- driver::clr_array(rdat2, parts = 2)
t.test(clr_rdat[1:n,1],clr_rdat[(n+1):(2*n),1])
library(ALDEx2)
mod <- aldex(t(rdat[,-1]),rdat[,1])
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = .1)
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = .5)
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[1,]))))
zz <- unlist(c(t.test.res[1,]))
mean(zz)
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = .25)
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[1,]))))
zz <- unlist(c(t.test.res[1,]))
mean(zz)
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = .05)
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[1,]))))
zz <- unlist(c(t.test.res[1,]))
mean(zz)
clr <- aldex.clr(t(rdat[,-1]), rdat[,1], gamma = .1)
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[1,]))))
zz <- unlist(c(t.test.res[1,]))
mean(zz)
sum(zz < -2)
sum(zz > -2)
38/128
clr <- aldex.clr(t(rdat[,-1]), rdat[,1])
t.test.res <- aldex.ttest2(clr)
plot(density(unlist(c(t.test.res[1,]))))
zz <- unlist(c(t.test.res[1,]))
mean(zz)
